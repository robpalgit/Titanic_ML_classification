{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Downton, Mr. William James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                        Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                         891   891   \n",
       "unique          NaN         NaN         NaN                         891     2   \n",
       "top             NaN         NaN         NaN  Downton, Mr. William James  male   \n",
       "freq            NaN         NaN         NaN                           1   577   \n",
       "mean     446.000000    0.383838    2.308642                         NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                         NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                         NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                         NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                         NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                         NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                         NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch Ticket        Fare        Cabin  \\\n",
       "count   714.000000  891.000000  891.000000    891  891.000000          204   \n",
       "unique         NaN         NaN         NaN    681         NaN          147   \n",
       "top            NaN         NaN         NaN   1601         NaN  C23 C25 C27   \n",
       "freq           NaN         NaN         NaN      7         NaN            4   \n",
       "mean     29.699118    0.523008    0.381594    NaN   32.204208          NaN   \n",
       "std      14.526497    1.102743    0.806057    NaN   49.693429          NaN   \n",
       "min       0.420000    0.000000    0.000000    NaN    0.000000          NaN   \n",
       "25%      20.125000    0.000000    0.000000    NaN    7.910400          NaN   \n",
       "50%      28.000000    0.000000    0.000000    NaN   14.454200          NaN   \n",
       "75%      38.000000    1.000000    0.000000    NaN   31.000000          NaN   \n",
       "max      80.000000    8.000000    6.000000    NaN  512.329200          NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Family_cnt  Cabin_ind\n",
       "0         0       3    0  22.0   7.2500           1          0\n",
       "1         1       1    1  38.0  71.2833           1          1\n",
       "2         1       3    1  26.0   7.9250           0          0\n",
       "3         1       1    1  35.0  53.1000           1          1\n",
       "4         0       3    0  35.0   8.0500           0          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "df['Family_cnt'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "df['Cabin_ind'] = np.where(df['Cabin'].isnull(), 0, 1)\n",
    "\n",
    "gender_num = {'male': 0, 'female': 1}\n",
    "df['Sex'] = df['Sex'].map(gender_num)\n",
    "\n",
    "df.drop(['SibSp', 'Parch', 'Cabin', 'Embarked', 'PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation / Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "features = df.drop('Survived', axis=1)\n",
    "labels = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_score(hp_optimizer):\n",
    "    print('BEST SCORE: {} - PARAMS: {}\\n'.format(round(hp_optimizer.best_score_, 3), hp_optimizer.best_params_))\n",
    "\n",
    "    means = hp_optimizer.cv_results_['mean_test_score']\n",
    "    stds = hp_optimizer.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, hp_optimizer.cv_results_['params']):\n",
    "        print('Score: {} (+/-{}) for Params: {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: 0.798 - PARAMS: {'C': 1}\n",
      "\n",
      "Score: 0.678 (+/-0.092) for Params: {'C': 0.001}\n",
      "Score: 0.704 (+/-0.099) for Params: {'C': 0.01}\n",
      "Score: 0.796 (+/-0.13) for Params: {'C': 0.1}\n",
      "Score: 0.798 (+/-0.123) for Params: {'C': 1}\n",
      "Score: 0.794 (+/-0.118) for Params: {'C': 10}\n",
      "Score: 0.794 (+/-0.118) for Params: {'C': 100}\n",
      "Score: 0.794 (+/-0.118) for Params: {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear')\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "CV_1 = GridSearchCV(lr, parameters, cv=5, iid=False)\n",
    "CV_1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_best_score(CV_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = CV_1.best_estimator_\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: 0.796 - PARAMS: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Score: 0.796 (+/-0.116) for Params: {'C': 0.1, 'kernel': 'linear'}\n",
      "Score: 0.654 (+/-0.062) for Params: {'C': 0.1, 'kernel': 'rbf'}\n",
      "Score: 0.796 (+/-0.116) for Params: {'C': 1, 'kernel': 'linear'}\n",
      "Score: 0.661 (+/-0.05) for Params: {'C': 1, 'kernel': 'rbf'}\n",
      "Score: 0.796 (+/-0.116) for Params: {'C': 100, 'kernel': 'linear'}\n",
      "Score: 0.788 (+/-0.113) for Params: {'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='scale')\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 100]\n",
    "}\n",
    "\n",
    "CV_2 = GridSearchCV(svc, parameters, cv=5, iid=False)\n",
    "CV_2.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_best_score(CV_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = CV_2.best_estimator_\n",
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: 0.811 - PARAMS: {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "\n",
      "Score: 0.717 (+/-0.226) for Params: {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "Score: 0.64 (+/-0.053) for Params: {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.581 (+/-0.327) for Params: {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.557 (+/-0.25) for Params: {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "Score: 0.618 (+/-0.024) for Params: {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.689 (+/-0.174) for Params: {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.575 (+/-0.201) for Params: {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "Score: 0.628 (+/-0.274) for Params: {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.618 (+/-0.234) for Params: {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.807 (+/-0.111) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "Score: 0.772 (+/-0.111) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.744 (+/-0.106) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.788 (+/-0.084) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "Score: 0.803 (+/-0.078) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.805 (+/-0.084) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.798 (+/-0.063) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "Score: 0.788 (+/-0.087) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.798 (+/-0.082) for Params: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.805 (+/-0.097) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "Score: 0.801 (+/-0.091) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.807 (+/-0.126) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.79 (+/-0.093) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "Score: 0.811 (+/-0.087) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.803 (+/-0.065) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "Score: 0.784 (+/-0.093) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "Score: 0.764 (+/-0.087) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "Score: 0.796 (+/-0.054) for Params: {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs')\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "CV_3 = GridSearchCV(mlp, parameters, cv=5, iid=False)\n",
    "CV_3.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_best_score(CV_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(50,), learning_rate='invscaling',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP = CV_3.best_estimator_\n",
    "MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: 0.831 - PARAMS: {'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "Score: 0.749 (+/-0.121) for Params: {'max_depth': 2, 'n_estimators': 5}\n",
      "Score: 0.79 (+/-0.133) for Params: {'max_depth': 2, 'n_estimators': 50}\n",
      "Score: 0.799 (+/-0.111) for Params: {'max_depth': 2, 'n_estimators': 250}\n",
      "Score: 0.809 (+/-0.125) for Params: {'max_depth': 4, 'n_estimators': 5}\n",
      "Score: 0.831 (+/-0.113) for Params: {'max_depth': 4, 'n_estimators': 50}\n",
      "Score: 0.822 (+/-0.109) for Params: {'max_depth': 4, 'n_estimators': 250}\n",
      "Score: 0.815 (+/-0.074) for Params: {'max_depth': 8, 'n_estimators': 5}\n",
      "Score: 0.824 (+/-0.079) for Params: {'max_depth': 8, 'n_estimators': 50}\n",
      "Score: 0.813 (+/-0.076) for Params: {'max_depth': 8, 'n_estimators': 250}\n",
      "Score: 0.815 (+/-0.039) for Params: {'max_depth': 16, 'n_estimators': 5}\n",
      "Score: 0.82 (+/-0.046) for Params: {'max_depth': 16, 'n_estimators': 50}\n",
      "Score: 0.815 (+/-0.032) for Params: {'max_depth': 16, 'n_estimators': 250}\n",
      "Score: 0.794 (+/-0.067) for Params: {'max_depth': 32, 'n_estimators': 5}\n",
      "Score: 0.813 (+/-0.027) for Params: {'max_depth': 32, 'n_estimators': 50}\n",
      "Score: 0.815 (+/-0.031) for Params: {'max_depth': 32, 'n_estimators': 250}\n",
      "Score: 0.792 (+/-0.065) for Params: {'max_depth': None, 'n_estimators': 5}\n",
      "Score: 0.811 (+/-0.029) for Params: {'max_depth': None, 'n_estimators': 50}\n",
      "Score: 0.809 (+/-0.028) for Params: {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "CV_4 = GridSearchCV(rf, parameters, cv=5, iid=False)\n",
    "CV_4.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_best_score(CV_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = CV_4.best_estimator_\n",
    "RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: 0.841 - PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "Score: 0.624 (+/-0.005) for Params: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "Score: 0.796 (+/-0.116) for Params: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "Score: 0.796 (+/-0.116) for Params: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "Score: 0.811 (+/-0.118) for Params: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "Score: 0.624 (+/-0.005) for Params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "Score: 0.811 (+/-0.071) for Params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Score: 0.829 (+/-0.076) for Params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "Score: 0.841 (+/-0.079) for Params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Score: 0.624 (+/-0.005) for Params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "Score: 0.82 (+/-0.052) for Params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "Score: 0.818 (+/-0.045) for Params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "Score: 0.831 (+/-0.038) for Params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "Score: 0.624 (+/-0.005) for Params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "Score: 0.818 (+/-0.054) for Params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "Score: 0.82 (+/-0.036) for Params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "Score: 0.805 (+/-0.019) for Params: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "Score: 0.624 (+/-0.005) for Params: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "Score: 0.801 (+/-0.055) for Params: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "Score: 0.807 (+/-0.027) for Params: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "Score: 0.779 (+/-0.033) for Params: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "Score: 0.796 (+/-0.116) for Params: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "Score: 0.815 (+/-0.119) for Params: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Score: 0.818 (+/-0.112) for Params: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "Score: 0.828 (+/-0.093) for Params: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "Score: 0.813 (+/-0.074) for Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "Score: 0.837 (+/-0.077) for Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Score: 0.83 (+/-0.04) for Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Score: 0.811 (+/-0.03) for Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Score: 0.815 (+/-0.046) for Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "Score: 0.826 (+/-0.014) for Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Score: 0.8 (+/-0.063) for Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Score: 0.803 (+/-0.046) for Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "Score: 0.822 (+/-0.057) for Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "Score: 0.79 (+/-0.039) for Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "Score: 0.803 (+/-0.041) for Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "Score: 0.798 (+/-0.044) for Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Score: 0.796 (+/-0.037) for Params: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "Score: 0.79 (+/-0.05) for Params: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Score: 0.785 (+/-0.025) for Params: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Score: 0.79 (+/-0.047) for Params: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "Score: 0.818 (+/-0.1) for Params: {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "Score: 0.83 (+/-0.078) for Params: {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Score: 0.828 (+/-0.069) for Params: {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "Score: 0.818 (+/-0.082) for Params: {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "Score: 0.82 (+/-0.063) for Params: {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "Score: 0.794 (+/-0.038) for Params: {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Score: 0.802 (+/-0.049) for Params: {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Score: 0.8 (+/-0.054) for Params: {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Score: 0.798 (+/-0.048) for Params: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "Score: 0.8 (+/-0.044) for Params: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Score: 0.8 (+/-0.073) for Params: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Score: 0.794 (+/-0.092) for Params: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "Score: 0.79 (+/-0.024) for Params: {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "Score: 0.801 (+/-0.051) for Params: {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "Score: 0.803 (+/-0.059) for Params: {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "Score: 0.79 (+/-0.055) for Params: {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Score: 0.764 (+/-0.018) for Params: {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "Score: 0.788 (+/-0.042) for Params: {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Score: 0.788 (+/-0.027) for Params: {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Score: 0.787 (+/-0.037) for Params: {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "Score: 0.204 (+/-0.116) for Params: {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "Score: 0.204 (+/-0.116) for Params: {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "Score: 0.204 (+/-0.116) for Params: {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "Score: 0.204 (+/-0.116) for Params: {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n",
      "Score: 0.31 (+/-0.192) for Params: {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "Score: 0.31 (+/-0.192) for Params: {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "Score: 0.31 (+/-0.192) for Params: {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "Score: 0.31 (+/-0.192) for Params: {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n",
      "Score: 0.468 (+/-0.313) for Params: {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "Score: 0.443 (+/-0.311) for Params: {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "Score: 0.493 (+/-0.367) for Params: {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "Score: 0.445 (+/-0.314) for Params: {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n",
      "Score: 0.611 (+/-0.178) for Params: {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "Score: 0.62 (+/-0.127) for Params: {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "Score: 0.603 (+/-0.134) for Params: {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "Score: 0.585 (+/-0.199) for Params: {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n",
      "Score: 0.715 (+/-0.134) for Params: {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "Score: 0.717 (+/-0.144) for Params: {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "Score: 0.726 (+/-0.128) for Params: {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "Score: 0.71 (+/-0.127) for Params: {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n",
      "Score: 0.376 (+/-0.005) for Params: {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "Score: 0.376 (+/-0.005) for Params: {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "Score: 0.376 (+/-0.005) for Params: {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "Score: 0.376 (+/-0.005) for Params: {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "Score: 0.29 (+/-0.104) for Params: {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "Score: 0.29 (+/-0.104) for Params: {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "Score: 0.29 (+/-0.104) for Params: {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "Score: 0.29 (+/-0.104) for Params: {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "Score: 0.38 (+/-0.187) for Params: {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "Score: 0.367 (+/-0.173) for Params: {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "Score: 0.376 (+/-0.175) for Params: {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "Score: 0.378 (+/-0.179) for Params: {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "Score: 0.577 (+/-0.108) for Params: {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "Score: 0.569 (+/-0.102) for Params: {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "Score: 0.592 (+/-0.107) for Params: {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "Score: 0.588 (+/-0.089) for Params: {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "Score: 0.65 (+/-0.072) for Params: {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "Score: 0.67 (+/-0.085) for Params: {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "Score: 0.678 (+/-0.102) for Params: {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "Score: 0.661 (+/-0.057) for Params: {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "CV_5 = GridSearchCV(gb, parameters, cv=5, iid=False)\n",
    "CV_5.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_best_score(CV_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB = CV_5.best_estimator_\n",
    "GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of best models on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_names = ['LR', 'SVM', 'MLP', 'RF', 'GB']\n",
    "mdl_list = [LR, SVM, MLP, RF, GB]\n",
    "models = dict(zip(mdl_names, mdl_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- Accuracy: 0.77 / Precision: 0.707 / Recall: 0.631 / Latency: 296.7ms\n",
      "SVM -- Accuracy: 0.747 / Precision: 0.672 / Recall: 0.6 / Latency: 15.6ms\n",
      "MLP -- Accuracy: 0.775 / Precision: 0.736 / Recall: 0.6 / Latency: 15.4ms\n",
      "RF -- Accuracy: 0.815 / Precision: 0.833 / Recall: 0.615 / Latency: 31.3ms\n",
      "GB -- Accuracy: 0.815 / Precision: 0.808 / Recall: 0.646 / Latency: 15.6ms\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting -- Accuracy: 0.816 / Precision: 0.852 / Recall: 0.684 / Latency: 31.3ms\n"
     ]
    }
   ],
   "source": [
    "evaluate_model('Gradient Boosting', models['GB'], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
